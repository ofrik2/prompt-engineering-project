# Default configuration for prompt-engineering experiments

model:
  provider: "dummy"        # placeholder for now, can change later
  model_name: "gpt-4.1-mini"  # or any string you want
  temperature: 0.2
  max_tokens: 256

experiment:
  name: "baseline_vs_cot_fewshot"
  methods:
    - "baseline"
    - "cot"
    - "fewshot"
  dataset: "file"
  dataset_path: "data/tasks_v1.json"
  output_dir: "results"

fewshot_examples:
  - { input: "I loved the dinner, it was great.", output: "positive" }
  - { input: "I hated the movie, it was terrible.", output: "negative" }


