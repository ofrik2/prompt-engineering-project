# Default configuration for prompt-engineering experiments

model:
  provider: "dummy"        # placeholder for now, can change later
  model_name: "gpt-4.1-mini"  # or any string you want
  temperature: 0.2
  max_tokens: 256

experiment:
  name: "baseline_vs_cot_dummy"
  methods:
    - "baseline"
    - "cot"
  dataset: "file"              # options: "dummy" or "file"
  dataset_path: "data/tasks_v1.json"
  output_dir: "results"

